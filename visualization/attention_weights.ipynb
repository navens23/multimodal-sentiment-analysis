{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Attention Weights\n",
    "\n",
    "This notebook visualizes the attention weights for the multimodal sentiment analysis model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer\n",
    "from models import MultimodalSentimentModel\n",
    "from dataset import AmazonReviewDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = MultimodalSentimentModel(num_labels=3)  # Adjust num_labels as needed\n",
    "model.load_state_dict(torch.load('path/to/model_checkpoint.pth'))  # Load your trained model checkpoint\n",
    "model.eval()\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('path/to/amazon_reviews.csv')\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "dataset = AmazonReviewDataset(df, 'text', 'image_path', 'label', tokenizer, transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Visualize attention weights\n",
    "def visualize_attention(text, image, attention_weight, label, prediction):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh([text], [attention_weight])\n",
    "    plt.xlabel('Attention Weight')\n",
    "    plt.title(f'True Label: {label}, Prediction: {prediction}')\n",
    "    plt.show()\n",
    "\n",
    "# Iterate through the dataloader and visualize\n",
    "with torch.no_grad():\n",
    "    for i, (text_inputs, images, labels, original_images) in enumerate(dataloader):\n",
    "        if i >= 5:  # Visualize 5 examples\n",
    "            break\n",
    "        text_inputs = {key: value for key, value in text_inputs.items()}\n",
    "        outputs = model(text_inputs, images)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        attention_weights = model.cross_attention.attention_weights.cpu().numpy()\n",
    "        visualize_attention(tokenizer.decode(text_inputs['input_ids'][0], skip_special_tokens=True), original_images[0], attention_weights[0][0][0], labels[0].item(), preds[0].item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
